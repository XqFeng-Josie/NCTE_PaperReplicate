{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ae774208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "================================================================================\n",
      "data loaded:\n",
      "- Utterances: 580,408\n",
      "- Paired annotations: 2,348\n",
      "- Student reasoning: 2,000\n",
      "- Classroom obs: 6,206\n",
      "- Teacher VA: 314\n",
      "- MQI data: 28,850\n",
      "- Student metadata: 12,661\n",
      "- Teacher metadata: 313\n",
      "unique observation ID (OBSID) in utterances: 1660\n",
      "unique observation ID (OBSID) in paired: 776\n",
      "unique observation ID (OBSID) in student_reasoning: 744\n",
      "unique teacher ID (NCTETID) in student_reasoning: 276\n",
      "unique observation ID (OBSID) in classroom_obs: 1713\n",
      "unique teacher ID (NCTETID) in classroom_obs: 317\n",
      "unique observation ID (OBSID) in mqi: 1694\n",
      "unique teacher ID (NCTETID) in mqi: 317\n",
      "common observation ID (OBSID) in utterances and mqi: 1660\n",
      "common observation ID (OBSID) in utterances and reasoning: 744\n",
      "common observation ID (OBSID) in paired and reasoning: 364\n",
      "common combox_idx ID (comb_idx) in utterances and reasoning: 2000\n",
      "common combox_idx ID (comb_idx) in paired and reasoning: 61\n",
      "common teacher ID (NCTETID) in student_reasoning and mqi: 276\n",
      "common observation ID (OBSID) in student_reasoning and mqi: 744\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_all_data():\n",
    "    print(\"=\"*80)\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. original data\n",
    "    utterances = pd.read_csv('data/ncte_single_utterances.csv')  # ['speaker', 'text', 'year', 'OBSID', 'video_id', 'cleaned_text', 'num_words', 'turn_idx', 'comb_idx']\n",
    "    paired = pd.read_csv('data/paired_annotations.csv') # ['exchange_idx', 'OBSID', 'student_text', 'teacher_text', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question']\n",
    "    reasoning = pd.read_csv('data/student_reasoning.csv') #['comb_idx', 'OBSID', 'NCTETID', 'text', 'student_reasoning', 'annotator_comment']\n",
    "    \n",
    "    # 2. CLASS observation\n",
    "    classroom_obs = pd.read_csv('ICPSR_36095/DS0001/36095-0001-Data.tsv', sep='\\t') \n",
    "    # ['NCTETID', 'DISTRICT', 'CLASS_11', 'CLASS_12', 'CLASS_13', 'SCHOOLYEAR_SP',\n",
    "    #  'OBSID', 'RATERID', 'OBSYEAR', 'OBSMONTH', 'OBSDAY', 'CHAPNUM', 'CLPC', 'CLNC',\n",
    "    #   'CLTS', 'CLRSP', 'CLBM', 'CLPRDT', 'CLILF', 'CLCU', 'CLAPS', 'CLQF', 'CLINSTD', 'CLSTENG']\n",
    "    \n",
    "    # 3. teacher value added\n",
    "    teacher_va = pd.read_csv('ICPSR_36095/DS0004/36095-0004-Data.tsv', sep='\\t')\n",
    "    # ['DISTRICT', 'NCTETID', 'STATEVA_M', \n",
    "    \n",
    "    # 4. MQI\n",
    "    mqi_data = pd.read_csv('ICPSR_36095/DS0002/36095-0002-Data.tsv', sep='\\t')\n",
    "    # ['NCTETID', 'DISTRICT', 'MQI5','OBSID', 'RATERID',\n",
    "    #    'SEGMENT', 'SCHOOLYEAR_SP', 'OBSYEAR', 'OBSMONTH', 'OBSDAY', 'CHAPNUM',\n",
    "    \n",
    "    # 5. student metadata (DS0005)\n",
    "    student_meta = pd.read_csv('ICPSR_36095/DS0005/36095-0005-Data.tsv', sep='\\t')\n",
    "    #['DISTRICT', 'SCHOOLID', 'NCTETID', 'CLASS_ID_M', 'NCTESID',\n",
    "    \n",
    "    # 6. teacher metadata (DS0006)  \n",
    "    teacher_meta = pd.read_csv('ICPSR_36095/DS0006/36095-0006-Data.tsv', sep='\\t')\n",
    "    # print(teacher_meta.columns)\n",
    "    # ['NCTETID', 'SURVEYYEAR_SP', 'EXPERIENCE', \n",
    "    \n",
    "    print(f\"data loaded:\")\n",
    "    print(f\"- Utterances: {len(utterances):,}\")\n",
    "    print(f\"- Paired annotations: {len(paired):,}\")\n",
    "    print(f\"- Student reasoning: {len(reasoning):,}\")\n",
    "    print(f\"- Classroom obs: {len(classroom_obs):,}\")\n",
    "    print(f\"- Teacher VA: {len(teacher_va):,}\")\n",
    "    print(f\"- MQI data: {len(mqi_data):,}\")\n",
    "    print(f\"- Student metadata: {len(student_meta):,}\")\n",
    "    print(f\"- Teacher metadata: {len(teacher_meta):,}\")\n",
    "\n",
    "\n",
    "    print(f\"unique observation ID (OBSID) in utterances: {utterances['OBSID'].nunique()}\")\n",
    "    print(f\"unique observation ID (OBSID) in paired: {paired['OBSID'].nunique()}\")\n",
    "    print(f\"unique observation ID (OBSID) in student_reasoning: {reasoning['OBSID'].nunique()}\")\n",
    "    print(f\"unique teacher ID (NCTETID) in student_reasoning: {reasoning['NCTETID'].nunique()}\")\n",
    "\n",
    "    print(f\"unique observation ID (OBSID) in classroom_obs: {classroom_obs['OBSID'].nunique()}\")\n",
    "    print(f\"unique teacher ID (NCTETID) in classroom_obs: {classroom_obs['NCTETID'].nunique()}\")\n",
    "    \n",
    "    print(f\"unique observation ID (OBSID) in mqi: {mqi_data['OBSID'].nunique()}\")\n",
    "    print(f\"unique teacher ID (NCTETID) in mqi: {mqi_data['NCTETID'].nunique()}\")\n",
    "    print(f\"common observation ID (OBSID) in utterances and mqi: {len(set(utterances['OBSID']) & set(mqi_data['OBSID']))}\")\n",
    "    print(f\"common observation ID (OBSID) in utterances and reasoning: {len(set(utterances['OBSID']) & set(reasoning['OBSID']))}\")\n",
    "    print(f\"common observation ID (OBSID) in paired and reasoning: {len(set(paired['OBSID']) & set(reasoning['OBSID']))}\")\n",
    "\n",
    "    print(f\"common combox_idx ID (comb_idx) in utterances and reasoning: {len(set(utterances['comb_idx']) & set(reasoning['comb_idx']))}\")\n",
    "    print(f\"common combox_idx ID (comb_idx) in paired and reasoning: {len(set(paired['exchange_idx']) & set(reasoning['comb_idx']))}\")\n",
    "\n",
    "\n",
    "    print(f\"common teacher ID (NCTETID) in student_reasoning and mqi: {len(set(reasoning['NCTETID']) & set(mqi_data['NCTETID']))}\")\n",
    "    print(f\"common observation ID (OBSID) in student_reasoning and mqi: {len(set(reasoning['OBSID']) & set(mqi_data['OBSID']))}\")\n",
    "\n",
    "    # print(mqi_data.columns)\n",
    "    return utterances, paired, reasoning, classroom_obs, teacher_va, mqi_data, student_meta, teacher_meta\n",
    "utterances, paired, reasoning, classroom_obs, teacher_va, mqi_data, student_meta, teacher_meta = load_all_data()\n",
    "\n",
    "\n",
    "# speaker: The speaker of the utterance.\n",
    "# text: The utterance text.\n",
    "# year: The school year in which transcript was taken. 1 = 2010-11, 2 = 2011-12, 3 = 2012-13 school year.\n",
    "# OBSID: The unique ID for the transcript. Observation ID, mappable to unique transcripts in the NCTE dataset.\n",
    "# video_id: The unique ID of the video from which the transcript was taken.\n",
    "# cleaned_text: The cleaned version of text with removed punctuation and lower casing.\n",
    "# num_words: Number of words in the utterance text.\n",
    "# turn_idx: The utterance turn number in the transcript.\n",
    "# comb_idx: The concatenation of OBSID and turn_idx, i.e., comb_idx = <OBSID>_<turn_idx>.\n",
    "\n",
    "# CLPC（Positive Climate)\n",
    "# CLRSP (Regard for Student Perspectives)\n",
    "# CLTS (Teacher Sensitivity)\n",
    "# CLINSTD (Instructional Dialogue)\n",
    "\n",
    "# MQI5 (Teacher's Classroom Management Index)\n",
    "\n",
    "# Value-added  map  year\n",
    "\n",
    "# 1 = 2010-11, ->  STATEVA_M11\n",
    "# 2 = 2011-12, ->  STATEVA_M12\n",
    "# 3 = 2012-13, ->  STATEVA_M13\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b57af116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1660/1660 [00:00<00:00, 2222.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBSID</th>\n",
       "      <th>total_turns</th>\n",
       "      <th>student_turns</th>\n",
       "      <th>total_words</th>\n",
       "      <th>student_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2119</td>\n",
       "      <td>323</td>\n",
       "      <td>159</td>\n",
       "      <td>5763</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBSID  total_turns  student_turns  total_words  student_words\n",
       "0   2119          323            159         5763            923"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create observation dict (total_turns, student_turns, total_words, student_words)\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "observation_dict =  []\n",
    "for obsid in tqdm(utterances['OBSID'].unique()):\n",
    "    utterances_df = utterances[utterances['OBSID'] == obsid]\n",
    "    total_turns = len(utterances_df)\n",
    "    student_turns = len(utterances_df[utterances_df['speaker'] == 'student'])\n",
    "    total_words = utterances_df['num_words'].sum()\n",
    "    student_words = utterances_df[utterances_df['speaker'] == 'student']['num_words'].sum()\n",
    "    observation_dict.append([obsid, total_turns, student_turns, total_words, student_words])\n",
    "\n",
    "observation_dict = pd.DataFrame(observation_dict)\n",
    "observation_dict.columns = ['OBSID', 'total_turns', 'student_turns', 'total_words', 'student_words']\n",
    "print(len(observation_dict))\n",
    "observation_dict.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7890e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_meta 12661 teacher_meta 313\n"
     ]
    }
   ],
   "source": [
    "# process data\n",
    "def process_data(student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va):\n",
    "    student_meta.loc[student_meta['S_MALE'] == ' ', 'S_MALE'] = 0\n",
    "    student_meta.loc[student_meta['S_AFAM'] == ' ', 'S_AFAM'] = 0\n",
    "    student_meta.loc[student_meta['S_WHITE'] == ' ', 'S_WHITE'] = 0\n",
    "    student_meta.loc[student_meta['S_HISP'] == ' ', 'S_HISP'] = 0\n",
    "    student_meta.loc[student_meta['S_ASIAN'] == ' ', 'S_ASIAN'] = 0\n",
    "    student_meta.loc[student_meta['S_RACE_OTHER'] == ' ', 'S_RACE_OTHER'] = 0\n",
    "    student_meta.loc[student_meta['S_FRPL'] == ' ', 'S_FRPL'] = 0\n",
    "    student_meta.loc[student_meta['S_SPED'] == ' ', 'S_SPED'] = 0\n",
    "    student_meta.loc[student_meta['S_LEP'] == ' ', 'S_LEP'] = 0\n",
    "\n",
    "    teacher_meta.loc[teacher_meta['MALE'] == ' ', 'MALE'] = 0\n",
    "    teacher_meta.loc[teacher_meta['BLACK'] == ' ', 'BLACK'] = 0\n",
    "    teacher_meta.loc[teacher_meta['WHITE'] == ' ', 'WHITE'] = 0\n",
    "    teacher_meta.loc[teacher_meta['HISP'] == ' ', 'HISP'] = 0\n",
    "    teacher_meta.loc[teacher_meta['ASIAN'] == ' ', 'ASIAN'] = 0\n",
    "    teacher_meta.loc[teacher_meta['EXPERIENCE'] == ' ', 'EXPERIENCE'] = 0\n",
    "    teacher_meta.loc[teacher_meta['RACEOTHER'] == ' ', 'RACEOTHER'] = 0\n",
    "    teacher_meta['EXPERIENCE'] = teacher_meta['EXPERIENCE'].astype(float)\n",
    "    print(\"student_meta\", len(student_meta), \"teacher_meta\", len(teacher_meta))\n",
    "    # 处理MQI数据\n",
    "    mqi_data = mqi_data[~mqi_data.MQI5.isin(['998','999',999,998,' '])]\n",
    "\n",
    "    # 处理 classroom_obs\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLPC.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLTS.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLRSP.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLINSTD.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs['CLPC'] = classroom_obs['CLPC'].astype(int)\n",
    "    classroom_obs['CLTS'] = classroom_obs['CLTS'].astype(int)\n",
    "    classroom_obs['CLRSP'] = classroom_obs['CLRSP'].astype(int)\n",
    "    classroom_obs['CLINSTD'] = classroom_obs['CLINSTD'].astype(int)\n",
    "\n",
    "    teacher_va['STATEVA_M11'] = teacher_va['STATEVA_M11'].replace(' ', 0)\n",
    "    teacher_va['STATEVA_M12'] = teacher_va['STATEVA_M12'].replace(' ', 0)\n",
    "    teacher_va['STATEVA_M13'] = teacher_va['STATEVA_M13'].replace(' ', 0)\n",
    "    teacher_va['STATEVA_M11'] = teacher_va['STATEVA_M11'].astype(float)\n",
    "    teacher_va['STATEVA_M12'] = teacher_va['STATEVA_M12'].astype(float)\n",
    "    teacher_va['STATEVA_M13'] = teacher_va['STATEVA_M13'].astype(float)\n",
    "\n",
    "\n",
    "    return student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va\n",
    "\n",
    "student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va = process_data(student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3e549559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.10897859931, 0.001507199951, -0.337306290865]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we should map the teacher valut data to the utterances of the same year\n",
    "utterances_year_dict =  utterances.set_index('OBSID')['year'].to_dict()\n",
    "teacher_val_dict = dict()\n",
    "for i, row in teacher_va.groupby('NCTETID'):\n",
    "    STATEVA_M11_mean = row['STATEVA_M11'].mean()\n",
    "    STATEVA_M12_mean = row['STATEVA_M12'].mean()\n",
    "    STATEVA_M13_mean = row['STATEVA_M13'].mean()\n",
    "    teacher_val_dict[i] = [STATEVA_M11_mean, STATEVA_M12_mean, STATEVA_M13_mean]\n",
    "teacher_val_dict[11001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9f0f3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_final_dataset(df, outcome_vars):\n",
    "    for var in outcome_vars:\n",
    "        if var in df.columns:\n",
    "            valid_data = df[var].dropna()\n",
    "            mean_val = valid_data.mean()\n",
    "            std_val = valid_data.std()\n",
    "            df[f'z_{var}'] = (df[var] - mean_val) / std_val\n",
    "    return df\n",
    "def extract_coef_se(result, var_name):\n",
    "    try:\n",
    "        coef = result.params[var_name]\n",
    "        se = result.bse[var_name]\n",
    "        return coef, se\n",
    "    except:\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c698cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat df length :  1654\n",
      "drop duplicates df length :  1653\n",
      "standardize  MQI5 and teacher_va\n",
      "MQI student_reasoning 725 \n",
      "MQI student_on_task 757 \n",
      "MQI teacher_on_task 757 \n",
      "MQI high_uptake 757 \n",
      "MQI focusing_question 757 \n",
      "MQI student_turn_precent 1653 \n",
      "MQI student_word_precent 1653 \n",
      "doing teacher_va df length :  1587\n",
      "teacher_va student_reasoning 713\n",
      "teacher_va student_on_task 737\n",
      "teacher_va teacher_on_task 737\n",
      "teacher_va high_uptake 737\n",
      "teacher_va focusing_question 737\n",
      "teacher_va student_turn_precent 1587\n",
      "teacher_va student_word_precent 1587\n"
     ]
    }
   ],
   "source": [
    "final_result =  defaultdict(dict)\n",
    "df = []\n",
    "for teacher_id in mqi_data['NCTETID'].unique():\n",
    "    if teacher_id not in teacher_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    if teacher_id not in student_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    student_metadata_df = student_meta[student_meta['NCTETID'] == teacher_id]\n",
    "    teacher_metadata_df = teacher_meta[teacher_meta['NCTETID'] == teacher_id]\n",
    "    s_male = student_metadata_df['S_MALE'].astype(int).mean()\n",
    "    s_afam = student_metadata_df['S_AFAM'].astype(int).mean()\n",
    "    s_white = student_metadata_df['S_WHITE'].astype(int).mean()\n",
    "    s_hisp = student_metadata_df['S_HISP'].astype(int).mean()\n",
    "    s_asian = student_metadata_df['S_ASIAN'].astype(int).mean()\n",
    "    s_race_other = student_metadata_df['S_RACE_OTHER'].astype(int).mean()\n",
    "    s_frpl = student_metadata_df['S_FRPL'].astype(int).mean()\n",
    "    s_sped = student_metadata_df['S_SPED'].astype(int).mean()\n",
    "    s_lep = student_metadata_df['S_LEP'].astype(int).mean()\n",
    "    t_male = teacher_metadata_df['MALE'].astype(int).mean()\n",
    "    t_black = teacher_metadata_df['BLACK'].astype(int).mean()\n",
    "    t_white = teacher_metadata_df['WHITE'].astype(int).mean()\n",
    "    t_hisp = teacher_metadata_df['HISP'].astype(int).mean()\n",
    "    t_asian = teacher_metadata_df['ASIAN'].astype(int).mean()\n",
    "    t_race_other = teacher_metadata_df['RACEOTHER'].astype(int).mean()\n",
    "    t_experience = teacher_metadata_df['EXPERIENCE'].mean()\n",
    "\n",
    "    mqi = mqi_data[mqi_data['NCTETID'] == teacher_id]\n",
    "    # z_scaler = StandardScaler()\n",
    "    # mqi['MQI5'] = z_scaler.fit_transform(mqi[['MQI5']])\n",
    "    for obsid in mqi['OBSID'].unique():\n",
    "        mqi_score = mqi[mqi['OBSID'] == obsid]['MQI5'].mean()\n",
    "        # print(year, obsid)\n",
    "        try:\n",
    "            year = utterances_year_dict[obsid]\n",
    "            teacher_va_score = teacher_val_dict[teacher_id][year-1]\n",
    "        except:\n",
    "            teacher_va_score = None\n",
    "        student_reasoning = reasoning[reasoning['OBSID'] == obsid]\n",
    "        paired_data = paired[paired['OBSID'] == obsid]\n",
    "        student_on_task = paired_data['student_on_task'].mean()\n",
    "        teacher_on_task = paired_data['teacher_on_task'].mean()\n",
    "        high_uptake = paired_data['high_uptake'].mean()\n",
    "        focusing_question = paired_data['focusing_question'].mean()\n",
    "        observation_dict_df = observation_dict[observation_dict['OBSID'] == obsid]\n",
    "        if len(observation_dict_df) > 0:\n",
    "            student_turn_precent = observation_dict_df['student_turns'].values[0] / observation_dict_df['total_turns'].values[0]\n",
    "            student_word_precent = observation_dict_df['student_words'].values[0] / observation_dict_df['total_words'].values[0]\n",
    "            observation = len(observation_dict_df)\n",
    "        if len(student_reasoning) > 0 or len(paired_data) > 0 or len(observation_dict) > 0:\n",
    "            df.append({'NCTETID': teacher_id,\n",
    "             'MQI5': mqi_score,\n",
    "             'teacher_va': teacher_va_score,\n",
    "              'student_reasoning': student_reasoning.student_reasoning.mean() if len(student_reasoning) > 0 else None,\n",
    "              'student_on_task': student_on_task if len(paired_data) > 0 else None,\n",
    "              'teacher_on_task': teacher_on_task if len(paired_data) > 0 else None,\n",
    "              'high_uptake': high_uptake if len(paired_data) > 0 else None,\n",
    "              'focusing_question': focusing_question if len(paired_data) > 0 else None,\n",
    "              'student_turn_precent': student_turn_precent if len(observation_dict) > 0 else None,\n",
    "              'student_word_precent': student_word_precent if len(observation_dict) > 0 else None,\n",
    "              'observation': observation if len(observation_dict) > 0 else None,\n",
    "              's_male': s_male,\n",
    "              's_afam': s_afam,\n",
    "              's_white': s_white,\n",
    "              's_hisp': s_hisp,\n",
    "              's_asian': s_asian,\n",
    "              's_race_other': s_race_other,\n",
    "              's_frpl': s_frpl,\n",
    "              's_sped': s_sped,\n",
    "              's_lep': s_lep,\n",
    "              't_male': t_male,\n",
    "              't_black': t_black,\n",
    "              't_white': t_white,\n",
    "              't_hisp': t_hisp,\n",
    "              't_asian': t_asian,\n",
    "              't_race_other': t_race_other,\n",
    "              't_experience': t_experience,\n",
    "              })\n",
    "df = pd.DataFrame(df)\n",
    "print(\"concat df length : \", len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(\"drop duplicates df length : \", len(df))\n",
    "print(\"standardize  MQI5 and teacher_va\")\n",
    "df = standardize_final_dataset(df, ['MQI5', 'teacher_va'])\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "# 教师层面：性别（二进制）、种族（多分类）、教龄（连续值）；\n",
    "# 学生层面：性别占比、种族占比、免费午餐占比、特殊教育占比、英语非母语占比\n",
    "# MQI回归 - 使用标准化的z_MQI5\n",
    "for xlist in ['student_reasoning', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question', 'student_turn_precent', 'student_word_precent']:\n",
    "    df_mqi = df[df[xlist].notna() & df['z_MQI5'].notna()]\n",
    "    print(f\"MQI {xlist} {len(df_mqi)} \")\n",
    "    result = sm.ols(\n",
    "        formula=\n",
    "    \"\"\"z_MQI5 ~ {} + t_male + t_experience + t_race_other + s_male + s_white + s_asian + s_hisp + s_frpl + s_sped + s_lep \"\"\".format(xlist), data=df_mqi).fit()\n",
    "    coef, std_err = extract_coef_se(result, xlist)\n",
    "    final_result[xlist]['MQI'] = [coef, std_err]  \n",
    "\n",
    "# 价值增值回归 - 教师级别聚合\n",
    "df_va = df[df['teacher_va'].notna()].copy()\n",
    "print(\"doing teacher_va df length : \", len(df_va))\n",
    "# teacher_data = df_va.groupby('NCTETID').agg({\n",
    "#     'student_reasoning': 'mean',\n",
    "#     'student_on_task': 'mean', \n",
    "#     'teacher_on_task': 'mean',\n",
    "#     'high_uptake': 'mean',\n",
    "#     'focusing_question': 'mean',\n",
    "#     'student_turn_precent': 'mean',\n",
    "#     'student_word_precent': 'mean',\n",
    "#     'teacher_va': 'mean',\n",
    "#     't_male': 'first',\n",
    "#     't_experience': 'first',\n",
    "#     't_race_other': 'first',\n",
    "#     's_male': 'mean',\n",
    "#     's_white': 'mean',\n",
    "#     's_asian': 'mean',\n",
    "#     's_hisp': 'mean',\n",
    "#     's_frpl': 'mean',\n",
    "#     's_sped': 'mean',\n",
    "#     's_lep': 'mean'\n",
    "# }).reset_index()\n",
    "\n",
    "# 标准化价值增值\n",
    "df_va = standardize_final_dataset(df_va, ['teacher_va'])\n",
    "for xlist in ['student_reasoning', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question', 'student_turn_precent', 'student_word_precent']:\n",
    "    df_val = df_va[df_va[xlist].notna() & df_va['z_teacher_va'].notna()]\n",
    "    print(f\"teacher_va {xlist} {len(df_val)}\")\n",
    "    result = sm.ols(\n",
    "        formula=\n",
    "    \"\"\"z_teacher_va ~ {} + t_male + t_experience + t_race_other + s_male + s_white + s_asian + s_hisp + s_frpl + s_sped + s_lep \"\"\".format(xlist), data=df_val).fit()\n",
    "    coef, std_err = extract_coef_se(result, xlist)\n",
    "    final_result[xlist]['teacher_va'] = [coef, std_err]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "833933c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop duplicates df length :  1670\n",
      "standardize clpc, clts, clrsp, clinstd\n",
      "clpc student_reasoning 725\n",
      "clpc student_on_task 757\n",
      "clpc teacher_on_task 757\n",
      "clpc high_uptake 757\n",
      "clpc focusing_question 757\n",
      "clpc student_turn_precent 1670\n",
      "clpc student_word_precent 1670\n",
      "clts student_reasoning 725\n",
      "clts student_on_task 757\n",
      "clts teacher_on_task 757\n",
      "clts high_uptake 757\n",
      "clts focusing_question 757\n",
      "clts student_turn_precent 1670\n",
      "clts student_word_precent 1670\n",
      "clrsp student_reasoning 725\n",
      "clrsp student_on_task 757\n",
      "clrsp teacher_on_task 757\n",
      "clrsp high_uptake 757\n",
      "clrsp focusing_question 757\n",
      "clrsp student_turn_precent 1670\n",
      "clrsp student_word_precent 1670\n",
      "clinstd student_reasoning 725\n",
      "clinstd student_on_task 757\n",
      "clinstd teacher_on_task 757\n",
      "clinstd high_uptake 757\n",
      "clinstd focusing_question 757\n",
      "clinstd student_turn_precent 1670\n",
      "clinstd student_word_precent 1670\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for teacher_id in classroom_obs['NCTETID'].unique():\n",
    "    if teacher_id not in teacher_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    if teacher_id not in student_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    student_metadata_df = student_meta[student_meta['NCTETID'] == teacher_id]\n",
    "    teacher_metadata_df = teacher_meta[teacher_meta['NCTETID'] == teacher_id]\n",
    "    s_male = student_metadata_df['S_MALE'].astype(int).mean()\n",
    "    s_afam = student_metadata_df['S_AFAM'].astype(int).mean()\n",
    "    s_white = student_metadata_df['S_WHITE'].astype(int).mean()\n",
    "    s_hisp = student_metadata_df['S_HISP'].astype(int).mean()\n",
    "    s_asian = student_metadata_df['S_ASIAN'].astype(int).mean()\n",
    "    s_race_other = student_metadata_df['S_RACE_OTHER'].astype(int).mean()\n",
    "    s_frpl = student_metadata_df['S_FRPL'].astype(int).mean()\n",
    "    s_sped = student_metadata_df['S_SPED'].astype(int).mean()\n",
    "    s_lep = student_metadata_df['S_LEP'].astype(int).mean()\n",
    "    t_male = teacher_metadata_df['MALE'].astype(int).mean()\n",
    "    t_black = teacher_metadata_df['BLACK'].astype(int).mean()\n",
    "    t_white = teacher_metadata_df['WHITE'].astype(int).mean()\n",
    "    t_hisp = teacher_metadata_df['HISP'].astype(int).mean()\n",
    "    t_asian = teacher_metadata_df['ASIAN'].astype(int).mean()\n",
    "    t_race_other = teacher_metadata_df['RACEOTHER'].astype(int).mean()\n",
    "    t_experience = teacher_metadata_df['EXPERIENCE'].mean()\n",
    "\n",
    "    classroom_obs_df = classroom_obs[classroom_obs['NCTETID'] == teacher_id]\n",
    "    for obsid in classroom_obs_df['OBSID'].unique():\n",
    "        \n",
    "        clpc = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLPC'].mean()\n",
    "        clts = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLTS'].mean()\n",
    "        clrsp = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLRSP'].mean()\n",
    "        clinstd = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLINSTD'].mean()\n",
    "        student_reasoning = reasoning[reasoning['OBSID'] == obsid]\n",
    "        paired_data = paired[paired['OBSID'] == obsid]\n",
    "        student_on_task = paired_data['student_on_task'].mean()\n",
    "        teacher_on_task = paired_data['teacher_on_task'].mean()\n",
    "        high_uptake = paired_data['high_uptake'].mean()\n",
    "        focusing_question = paired_data['focusing_question'].mean()\n",
    "        observation_dict_df = observation_dict[observation_dict['OBSID'] == obsid]\n",
    "        if len(observation_dict_df) > 0:\n",
    "            student_turn_precent = observation_dict_df['student_turns'].values[0] / observation_dict_df['total_turns'].values[0]\n",
    "            student_word_precent = observation_dict_df['student_words'].values[0] / observation_dict_df['total_words'].values[0]\n",
    "            observation = len(observation_dict_df)\n",
    "        if len(student_reasoning) > 0 or len(paired_data) > 0 or len(observation_dict) > 0:\n",
    "            df.append({'NCTETID': teacher_id,\n",
    "            #  'MQI5': mqi_score,\n",
    "            'clpc': clpc,\n",
    "            'clts': clts,\n",
    "            'clrsp': clrsp,\n",
    "            'clinstd': clinstd,\n",
    "              'student_reasoning': student_reasoning.student_reasoning.mean() if len(student_reasoning) > 0 else None,\n",
    "              'student_on_task': student_on_task if len(paired_data) > 0 else None,\n",
    "              'teacher_on_task': teacher_on_task if len(paired_data) > 0 else None,\n",
    "              'high_uptake': high_uptake if len(paired_data) > 0 else None,\n",
    "              'focusing_question': focusing_question if len(paired_data) > 0 else None,\n",
    "              'student_turn_precent': student_turn_precent if len(observation_dict) > 0 else None,\n",
    "              'student_word_precent': student_word_precent if len(observation_dict) > 0 else None,\n",
    "              'observation': observation if len(observation_dict) > 0 else None,\n",
    "              's_male': s_male,\n",
    "              's_afam': s_afam,\n",
    "              's_white': s_white,\n",
    "              's_hisp': s_hisp,\n",
    "              's_asian': s_asian,\n",
    "              's_race_other': s_race_other,\n",
    "              's_frpl': s_frpl,\n",
    "              's_sped': s_sped,\n",
    "              's_lep': s_lep,\n",
    "              't_male': t_male,\n",
    "              't_black': t_black,\n",
    "              't_white': t_white,\n",
    "              't_hisp': t_hisp,\n",
    "              't_asian': t_asian,\n",
    "              't_race_other': t_race_other,\n",
    "              't_experience': t_experience,\n",
    "              })\n",
    "df = pd.DataFrame(df)\n",
    "df = df.drop_duplicates()\n",
    "print(\"drop duplicates df length : \", len(df))\n",
    "print(\"standardize clpc, clts, clrsp, clinstd\")\n",
    "df = standardize_final_dataset(df, ['clpc', 'clts', 'clrsp', 'clinstd'])\n",
    "import statsmodels.formula.api as sm\n",
    "# 教师层面：性别（二进制）、种族（多分类）、教龄（连续值）；\n",
    "# 学生层面：性别占比、种族占比、免费午餐占比、特殊教育占比、英语非母语占比\n",
    "# CLASS回归 - 使用标准化的z_变量\n",
    "for ylist in ['clpc', 'clts', 'clrsp', 'clinstd']:\n",
    "    for xlist in ['student_reasoning', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question', 'student_turn_precent', 'student_word_precent']:\n",
    "        df_mqi = df[df[xlist].notna() & df[f'z_{ylist}'].notna()]\n",
    "        print(f\"{ylist} {xlist} {len(df_mqi)}\")\n",
    "        result = sm.ols(\n",
    "            formula=\n",
    "        \"\"\" z_{} ~ {} + t_male + t_experience + t_race_other + s_male + s_white + s_asian + s_hisp + s_frpl + s_sped + s_lep \"\"\".format(ylist, xlist), data=df_mqi).fit()\n",
    "        coef, std_err = extract_coef_se(result, xlist)\n",
    "        final_result[xlist][ylist] = [coef, std_err]\n",
    "# final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0089808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result\n",
    "final_result_list = []\n",
    "for xlist in final_result.keys():\n",
    "    one_list = [xlist]\n",
    "    keys = ['teacher_va','MQI', 'clinstd','clts',  'clrsp',  'clpc']\n",
    "    for ylist in keys:\n",
    "        one_list.append(final_result[xlist][ylist][0])\n",
    "        one_list.append(final_result[xlist][ylist][1])\n",
    "    final_result_list.append(one_list)\n",
    "final_result_list = pd.DataFrame(final_result_list,columns=['x','teacher_va_coef','teacher_va_std','MQI_coef','MQI_std','clinstd_coef','clinstd_std','clts_coef','clts_std','clrsp_coef','clrsp_std','clpc_coef','clpc_std'])\n",
    "final_result_list = final_result_list.round(3)\n",
    "x_map = {\n",
    "    'student_reasoning': 'Student Reasoning(Our)',\n",
    "    'student_on_task': 'Student on Task(Our)',\n",
    "    'teacher_on_task': 'Teacher on Task(Our)',\n",
    "    'high_uptake': 'Teacher Uptake(Our)',\n",
    "    'focusing_question': 'Focusing Question(Our)',\n",
    "    'student_turn_precent': 'Student Turn(Our)',\n",
    "    'student_word_precent': 'Student Word(Our)',\n",
    "    'observation': 'Observation'\n",
    "}\n",
    "final_result_list['x'] = final_result_list['x'].map(x_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0119f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table5_result = pd.read_csv('paper/table5.csv',sep='\\t')\n",
    "# concat the table5_result and final_result_list, in axis 0\n",
    "merged_result = pd.concat([table5_result, final_result_list], axis=0)\n",
    "merged_result = merged_result.sort_values(by='x').reset_index(drop=True)\n",
    "def convert_dataframe_to_markdown(df, filename):\n",
    "    # left align the first column\n",
    "\n",
    "    markdown_table = df.to_markdown(index=False, stralign='center')\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(markdown_table)\n",
    "\n",
    "# 使用示例\n",
    "convert_dataframe_to_markdown(merged_result, 'merged_result.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1fa15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342aaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
