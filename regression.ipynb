{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eaba0b6",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae774208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "================================================================================\n",
      "data loaded:\n",
      "- Utterances: 580,408\n",
      "- Paired annotations: 2,348\n",
      "- Student reasoning: 2,000\n",
      "- Classroom obs: 6,206\n",
      "- Teacher VA: 314\n",
      "- MQI data: 28,850\n",
      "- Student metadata: 12,661\n",
      "- Teacher metadata: 313\n",
      "unique observation ID (OBSID) in utterances: 1660\n",
      "unique observation ID (OBSID) in paired: 776\n",
      "unique observation ID (OBSID) in student_reasoning: 744\n",
      "unique teacher ID (NCTETID) in student_reasoning: 276\n",
      "unique observation ID (OBSID) in classroom_obs: 1713\n",
      "unique teacher ID (NCTETID) in classroom_obs: 317\n",
      "unique observation ID (OBSID) in mqi: 1694\n",
      "unique teacher ID (NCTETID) in mqi: 317\n",
      "common observation ID (OBSID) in utterances and mqi: 1660\n",
      "common observation ID (OBSID) in utterances and reasoning: 744\n",
      "common observation ID (OBSID) in paired and reasoning: 364\n",
      "common combox_idx ID (comb_idx) in utterances and reasoning: 2000\n",
      "common combox_idx ID (comb_idx) in paired and reasoning: 61\n",
      "common teacher ID (NCTETID) in student_reasoning and mqi: 276\n",
      "common observation ID (OBSID) in student_reasoning and mqi: 744\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_all_data():\n",
    "    print(\"=\"*80)\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. original data\n",
    "    utterances = pd.read_csv('data/ncte_single_utterances.csv')  # ['speaker', 'text', 'year', 'OBSID', 'video_id', 'cleaned_text', 'num_words', 'turn_idx', 'comb_idx']\n",
    "    paired = pd.read_csv('data/paired_annotations.csv') # ['exchange_idx', 'OBSID', 'student_text', 'teacher_text', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question']\n",
    "    reasoning = pd.read_csv('data/student_reasoning.csv') #['comb_idx', 'OBSID', 'NCTETID', 'text', 'student_reasoning', 'annotator_comment']\n",
    "    \n",
    "    # 2. CLASS observation\n",
    "    classroom_obs = pd.read_csv('ICPSR_36095/DS0001/36095-0001-Data.tsv', sep='\\t') \n",
    "    # ['NCTETID', 'DISTRICT', 'CLASS_11', 'CLASS_12', 'CLASS_13', 'SCHOOLYEAR_SP',\n",
    "    #  'OBSID', 'RATERID', 'OBSYEAR', 'OBSMONTH', 'OBSDAY', 'CHAPNUM', 'CLPC', 'CLNC',\n",
    "    #   'CLTS', 'CLRSP', 'CLBM', 'CLPRDT', 'CLILF', 'CLCU', 'CLAPS', 'CLQF', 'CLINSTD', 'CLSTENG']\n",
    "    \n",
    "    # 3. teacher value added\n",
    "    teacher_va = pd.read_csv('ICPSR_36095/DS0004/36095-0004-Data.tsv', sep='\\t')\n",
    "    # ['DISTRICT', 'NCTETID', 'STATEVA_M', \n",
    "    \n",
    "    # 4. MQI\n",
    "    mqi_data = pd.read_csv('ICPSR_36095/DS0002/36095-0002-Data.tsv', sep='\\t')\n",
    "    # ['NCTETID', 'DISTRICT', 'MQI5','OBSID', 'RATERID',\n",
    "    #    'SEGMENT', 'SCHOOLYEAR_SP', 'OBSYEAR', 'OBSMONTH', 'OBSDAY', 'CHAPNUM',\n",
    "    \n",
    "    # 5. student metadata (DS0005)\n",
    "    student_meta = pd.read_csv('ICPSR_36095/DS0005/36095-0005-Data.tsv', sep='\\t')\n",
    "    #['DISTRICT', 'SCHOOLID', 'NCTETID', 'CLASS_ID_M', 'NCTESID',\n",
    "    \n",
    "    # 6. teacher metadata (DS0006)  \n",
    "    teacher_meta = pd.read_csv('ICPSR_36095/DS0006/36095-0006-Data.tsv', sep='\\t')\n",
    "    # print(teacher_meta.columns)\n",
    "    # ['NCTETID', 'SURVEYYEAR_SP', 'EXPERIENCE', \n",
    "    \n",
    "    print(f\"data loaded:\")\n",
    "    print(f\"- Utterances: {len(utterances):,}\")\n",
    "    print(f\"- Paired annotations: {len(paired):,}\")\n",
    "    print(f\"- Student reasoning: {len(reasoning):,}\")\n",
    "    print(f\"- Classroom obs: {len(classroom_obs):,}\")\n",
    "    print(f\"- Teacher VA: {len(teacher_va):,}\")\n",
    "    print(f\"- MQI data: {len(mqi_data):,}\")\n",
    "    print(f\"- Student metadata: {len(student_meta):,}\")\n",
    "    print(f\"- Teacher metadata: {len(teacher_meta):,}\")\n",
    "\n",
    "\n",
    "    print(f\"unique observation ID (OBSID) in utterances: {utterances['OBSID'].nunique()}\")\n",
    "    print(f\"unique observation ID (OBSID) in paired: {paired['OBSID'].nunique()}\")\n",
    "    print(f\"unique observation ID (OBSID) in student_reasoning: {reasoning['OBSID'].nunique()}\")\n",
    "    print(f\"unique teacher ID (NCTETID) in student_reasoning: {reasoning['NCTETID'].nunique()}\")\n",
    "\n",
    "    print(f\"unique observation ID (OBSID) in classroom_obs: {classroom_obs['OBSID'].nunique()}\")\n",
    "    print(f\"unique teacher ID (NCTETID) in classroom_obs: {classroom_obs['NCTETID'].nunique()}\")\n",
    "    \n",
    "    print(f\"unique observation ID (OBSID) in mqi: {mqi_data['OBSID'].nunique()}\")\n",
    "    print(f\"unique teacher ID (NCTETID) in mqi: {mqi_data['NCTETID'].nunique()}\")\n",
    "    print(f\"common observation ID (OBSID) in utterances and mqi: {len(set(utterances['OBSID']) & set(mqi_data['OBSID']))}\")\n",
    "    print(f\"common observation ID (OBSID) in utterances and reasoning: {len(set(utterances['OBSID']) & set(reasoning['OBSID']))}\")\n",
    "    print(f\"common observation ID (OBSID) in paired and reasoning: {len(set(paired['OBSID']) & set(reasoning['OBSID']))}\")\n",
    "\n",
    "    print(f\"common combox_idx ID (comb_idx) in utterances and reasoning: {len(set(utterances['comb_idx']) & set(reasoning['comb_idx']))}\")\n",
    "    print(f\"common combox_idx ID (comb_idx) in paired and reasoning: {len(set(paired['exchange_idx']) & set(reasoning['comb_idx']))}\")\n",
    "\n",
    "\n",
    "    print(f\"common teacher ID (NCTETID) in student_reasoning and mqi: {len(set(reasoning['NCTETID']) & set(mqi_data['NCTETID']))}\")\n",
    "    print(f\"common observation ID (OBSID) in student_reasoning and mqi: {len(set(reasoning['OBSID']) & set(mqi_data['OBSID']))}\")\n",
    "\n",
    "    # print(mqi_data.columns)\n",
    "    return utterances, paired, reasoning, classroom_obs, teacher_va, mqi_data, student_meta, teacher_meta\n",
    "utterances, paired, reasoning, classroom_obs, teacher_va, mqi_data, student_meta, teacher_meta = load_all_data()\n",
    "\n",
    "\n",
    "# speaker: The speaker of the utterance.\n",
    "# text: The utterance text.\n",
    "# year: The school year in which transcript was taken. 1 = 2010-11, 2 = 2011-12, 3 = 2012-13 school year.\n",
    "# OBSID: The unique ID for the transcript. Observation ID, mappable to unique transcripts in the NCTE dataset.\n",
    "# video_id: The unique ID of the video from which the transcript was taken.\n",
    "# cleaned_text: The cleaned version of text with removed punctuation and lower casing.\n",
    "# num_words: Number of words in the utterance text.\n",
    "# turn_idx: The utterance turn number in the transcript.\n",
    "# comb_idx: The concatenation of OBSID and turn_idx, i.e., comb_idx = <OBSID>_<turn_idx>.\n",
    "\n",
    "# CLPC（Positive Climate)\n",
    "# CLRSP (Regard for Student Perspectives)\n",
    "# CLTS (Teacher Sensitivity)\n",
    "# CLINSTD (Instructional Dialogue)\n",
    "\n",
    "# MQI5 (Teacher's Classroom Management Index)\n",
    "\n",
    "# Value-added  map  year\n",
    "\n",
    "# 1 = 2010-11, ->  STATEVA_M11\n",
    "# 2 = 2011-12, ->  STATEVA_M12\n",
    "# 3 = 2012-13, ->  STATEVA_M13\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29886fac",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "1. remove unvalid data from metadata (teacher/student...)\n",
    "2. create observation dict (total_turns, student_turns, total_words, student_words)\n",
    "3. teacher_val_dict (map to teacher year level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7890e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_meta 12661 teacher_meta 309\n"
     ]
    }
   ],
   "source": [
    "# process data\n",
    "def process_data(student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va):\n",
    "    student_meta.loc[student_meta['S_MALE'] == ' ', 'S_MALE'] = 0\n",
    "    student_meta.loc[student_meta['S_AFAM'] == ' ', 'S_AFAM'] = 0\n",
    "    student_meta.loc[student_meta['S_WHITE'] == ' ', 'S_WHITE'] = 0\n",
    "    student_meta.loc[student_meta['S_HISP'] == ' ', 'S_HISP'] = 0\n",
    "    student_meta.loc[student_meta['S_ASIAN'] == ' ', 'S_ASIAN'] = 0\n",
    "    student_meta.loc[student_meta['S_RACE_OTHER'] == ' ', 'S_RACE_OTHER'] = 0\n",
    "    student_meta.loc[student_meta['S_FRPL'] == ' ', 'S_FRPL'] = 0\n",
    "    student_meta.loc[student_meta['S_SPED'] == ' ', 'S_SPED'] = 0\n",
    "    student_meta.loc[student_meta['S_LEP'] == ' ', 'S_LEP'] = 0\n",
    "    # remove 998, 999, value 998 and 999 are missing values\n",
    "    student_meta = student_meta[~student_meta.S_MALE.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_AFAM.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_WHITE.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_HISP.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_ASIAN.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_RACE_OTHER.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_FRPL.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_SPED.isin(['998','999',999,998,' '])]\n",
    "    student_meta = student_meta[~student_meta.S_LEP.isin(['998','999',999,998,' '])]\n",
    "    \n",
    "    teacher_meta.loc[teacher_meta['MALE'] == ' ', 'MALE'] = 0\n",
    "    teacher_meta.loc[teacher_meta['BLACK'] == ' ', 'BLACK'] = 0\n",
    "    teacher_meta.loc[teacher_meta['WHITE'] == ' ', 'WHITE'] = 0\n",
    "    teacher_meta.loc[teacher_meta['HISP'] == ' ', 'HISP'] = 0\n",
    "    teacher_meta.loc[teacher_meta['ASIAN'] == ' ', 'ASIAN'] = 0\n",
    "    teacher_meta.loc[teacher_meta['EXPERIENCE'] == ' ', 'EXPERIENCE'] = 0\n",
    "    teacher_meta.loc[teacher_meta['RACEOTHER'] == ' ', 'RACEOTHER'] = 0\n",
    "    teacher_meta['EXPERIENCE'] = teacher_meta['EXPERIENCE'].astype(float)\n",
    "    \n",
    "    teacher_meta = teacher_meta[~teacher_meta.MALE.isin(['998','999',999,998,' '])]\n",
    "    teacher_meta = teacher_meta[~teacher_meta.BLACK.isin(['998','999',999,998,' '])]\n",
    "    teacher_meta = teacher_meta[~teacher_meta.WHITE.isin(['998','999',999,998,' '])]\n",
    "    teacher_meta = teacher_meta[~teacher_meta.HISP.isin(['998','999',999,998,' '])]\n",
    "    teacher_meta = teacher_meta[~teacher_meta.ASIAN.isin(['998','999',999,998,' '])]\n",
    "    teacher_meta = teacher_meta[~teacher_meta.RACEOTHER.isin(['998','999',999,998,' '])]\n",
    "\n",
    "    print(\"student_meta\", len(student_meta), \"teacher_meta\", len(teacher_meta))\n",
    "    # 处理MQI数据\n",
    "    mqi_data = mqi_data[~mqi_data.MQI5.isin(['998','999',999,998,' '])]\n",
    "\n",
    "    # 处理 classroom_obs\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLPC.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLTS.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLRSP.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs = classroom_obs[~classroom_obs.CLINSTD.isin(['998','999',999,998,' '])]\n",
    "    classroom_obs['CLPC'] = classroom_obs['CLPC'].astype(int)\n",
    "    classroom_obs['CLTS'] = classroom_obs['CLTS'].astype(int)\n",
    "    classroom_obs['CLRSP'] = classroom_obs['CLRSP'].astype(int)\n",
    "    classroom_obs['CLINSTD'] = classroom_obs['CLINSTD'].astype(int)\n",
    "\n",
    "    # Replace spaces with NaN instead of 0 to avoid bias\n",
    "    teacher_va['STATEVA_M11'] = teacher_va['STATEVA_M11'].replace(' ', np.nan)\n",
    "    teacher_va['STATEVA_M12'] = teacher_va['STATEVA_M12'].replace(' ', np.nan)\n",
    "    teacher_va['STATEVA_M13'] = teacher_va['STATEVA_M13'].replace(' ', np.nan)\n",
    "    teacher_va['STATEVA_M11'] = teacher_va['STATEVA_M11'].astype(float)\n",
    "    teacher_va['STATEVA_M12'] = teacher_va['STATEVA_M12'].astype(float)\n",
    "    teacher_va['STATEVA_M13'] = teacher_va['STATEVA_M13'].astype(float)\n",
    "\n",
    "\n",
    "    return student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va\n",
    "\n",
    "student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va = process_data(student_meta, teacher_meta, mqi_data, classroom_obs, teacher_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57af116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1660/1660 [00:00<00:00, 1728.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.10897859931, 0.001507199951, -0.337306290865]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create observation dict (total_turns, student_turns, total_words, student_words)\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "observation_dict =  []\n",
    "for obsid in tqdm(utterances['OBSID'].unique()):\n",
    "    utterances_df = utterances[utterances['OBSID'] == obsid]\n",
    "    total_turns = len(utterances_df)\n",
    "    student_turns = len(utterances_df[utterances_df['speaker'] == 'student'])\n",
    "    total_words = utterances_df['num_words'].sum()\n",
    "    student_words = utterances_df[utterances_df['speaker'] == 'student']['num_words'].sum()\n",
    "    observation_dict.append([obsid, total_turns, student_turns, total_words, student_words])\n",
    "\n",
    "observation_dict = pd.DataFrame(observation_dict)\n",
    "observation_dict.columns = ['OBSID', 'total_turns', 'student_turns', 'total_words', 'student_words']\n",
    "print(len(observation_dict))\n",
    "observation_dict.head(1)\n",
    "\n",
    "# we should map the teacher valut data to the utterances of the same year\n",
    "utterances_year_dict =  utterances.set_index('OBSID')['year'].to_dict()\n",
    "teacher_val_dict = dict()\n",
    "for i, row in teacher_va.groupby('NCTETID'):\n",
    "    # Use nanmean to handle NaN values properly\n",
    "    STATEVA_M11_mean = np.nanmean(row['STATEVA_M11']) if not row['STATEVA_M11'].isna().all() else np.nan\n",
    "    STATEVA_M12_mean = np.nanmean(row['STATEVA_M12']) if not row['STATEVA_M12'].isna().all() else np.nan\n",
    "    STATEVA_M13_mean = np.nanmean(row['STATEVA_M13']) if not row['STATEVA_M13'].isna().all() else np.nan\n",
    "    teacher_val_dict[i] = [STATEVA_M11_mean, STATEVA_M12_mean, STATEVA_M13_mean]\n",
    "teacher_val_dict[11001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0f3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_final_dataset(df, outcome_vars):\n",
    "    for var in outcome_vars:\n",
    "        if var in df.columns:\n",
    "            valid_data = df[var].dropna()\n",
    "            mean_val = valid_data.mean()\n",
    "            std_val = valid_data.std()\n",
    "            df[f'z_{var}'] = (df[var] - mean_val) / std_val\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_coef_se(result, var_name):\n",
    "    try:\n",
    "        coef = float(clustered_results.summary().tables[1].data[2][1])\n",
    "        se = float(clustered_results.summary().tables[1].data[2][2])\n",
    "        # coef = result.params[var_name]\n",
    "        # se = result.bse[var_name]\n",
    "        return coef, se\n",
    "    except:\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a82cb5",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "create data and do linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c698cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat df length :  1631\n",
      "drop duplicates df length :  1630\n",
      "standardize  MQI5 and teacher_va\n",
      "MQI student_reasoning 717 \n",
      "MQI student_on_task 744 \n",
      "MQI teacher_on_task 744 \n",
      "MQI high_uptake 744 \n",
      "MQI focusing_question 744 \n",
      "MQI student_turn_precent 1630 \n",
      "MQI student_word_precent 1630 \n",
      "doing teacher_va df length :  1523\n",
      "teacher_va student_reasoning 684\n",
      "teacher_va student_on_task 707\n",
      "teacher_va teacher_on_task 707\n",
      "teacher_va high_uptake 707\n",
      "teacher_va focusing_question 707\n",
      "teacher_va student_turn_precent 1523\n",
      "teacher_va student_word_precent 1523\n"
     ]
    }
   ],
   "source": [
    "final_result =  defaultdict(dict)\n",
    "df = []\n",
    "for teacher_id in mqi_data['NCTETID'].unique():\n",
    "    if teacher_id not in teacher_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    if teacher_id not in student_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    student_metadata_df = student_meta[student_meta['NCTETID'] == teacher_id]\n",
    "    teacher_metadata_df = teacher_meta[teacher_meta['NCTETID'] == teacher_id]\n",
    "    s_male = student_metadata_df['S_MALE'].astype(int).mean()\n",
    "    s_afam = student_metadata_df['S_AFAM'].astype(int).mean()\n",
    "    s_white = student_metadata_df['S_WHITE'].astype(int).mean()\n",
    "    s_hisp = student_metadata_df['S_HISP'].astype(int).mean()\n",
    "    s_asian = student_metadata_df['S_ASIAN'].astype(int).mean()\n",
    "    s_race_other = student_metadata_df['S_RACE_OTHER'].astype(int).mean()\n",
    "    s_frpl = student_metadata_df['S_FRPL'].astype(int).mean()\n",
    "    s_sped = student_metadata_df['S_SPED'].astype(int).mean()\n",
    "    s_lep = student_metadata_df['S_LEP'].astype(int).mean()\n",
    "    t_male = teacher_metadata_df['MALE'].astype(int).mean()\n",
    "    t_black = teacher_metadata_df['BLACK'].astype(int).mean()\n",
    "    t_white = teacher_metadata_df['WHITE'].astype(int).mean()\n",
    "    t_hisp = teacher_metadata_df['HISP'].astype(int).mean()\n",
    "    t_asian = teacher_metadata_df['ASIAN'].astype(int).mean()\n",
    "    t_race_other = teacher_metadata_df['RACEOTHER'].astype(int).mean()\n",
    "    t_experience = teacher_metadata_df['EXPERIENCE'].mean()\n",
    "\n",
    "    mqi = mqi_data[mqi_data['NCTETID'] == teacher_id]\n",
    "    for obsid in mqi['OBSID'].unique():\n",
    "        mqi_score = mqi[mqi['OBSID'] == obsid]['MQI5'].mean()\n",
    "        # print(year, obsid)\n",
    "        try:\n",
    "            year = utterances_year_dict[obsid]\n",
    "            teacher_va_score = teacher_val_dict[teacher_id][year-1]\n",
    "            # Handle NaN values\n",
    "            if pd.isna(teacher_va_score):\n",
    "                teacher_va_score = None\n",
    "        except:\n",
    "            teacher_va_score = None\n",
    "        student_reasoning = reasoning[reasoning['OBSID'] == obsid]\n",
    "        paired_data = paired[paired['OBSID'] == obsid]\n",
    "        student_on_task = paired_data['student_on_task'].mean()\n",
    "        teacher_on_task = paired_data['teacher_on_task'].mean()\n",
    "        high_uptake = paired_data['high_uptake'].mean()\n",
    "        focusing_question = paired_data['focusing_question'].mean()\n",
    "        observation_dict_df = observation_dict[observation_dict['OBSID'] == obsid]\n",
    "        if len(observation_dict_df) > 0:\n",
    "            student_turn_precent = observation_dict_df['student_turns'].values[0] / observation_dict_df['total_turns'].values[0]\n",
    "            student_word_precent = observation_dict_df['student_words'].values[0] / observation_dict_df['total_words'].values[0]\n",
    "            observation = len(observation_dict_df)\n",
    "        if len(student_reasoning) > 0 or len(paired_data) > 0 or len(observation_dict) > 0:\n",
    "            df.append({'NCTETID': teacher_id,\n",
    "             'MQI5': mqi_score,\n",
    "             'teacher_va': teacher_va_score,\n",
    "              'student_reasoning': student_reasoning.student_reasoning.mean() if len(student_reasoning) > 0 else None,\n",
    "              'student_on_task': student_on_task if len(paired_data) > 0 else None,\n",
    "              'teacher_on_task': teacher_on_task if len(paired_data) > 0 else None,\n",
    "              'high_uptake': high_uptake if len(paired_data) > 0 else None,\n",
    "              'focusing_question': focusing_question if len(paired_data) > 0 else None,\n",
    "              'student_turn_precent': student_turn_precent if len(observation_dict) > 0 else None,\n",
    "              'student_word_precent': student_word_precent if len(observation_dict) > 0 else None,\n",
    "              'observation': observation if len(observation_dict) > 0 else None,\n",
    "              's_male': s_male,\n",
    "              's_afam': s_afam,\n",
    "              's_white': s_white,\n",
    "              's_hisp': s_hisp,\n",
    "              's_asian': s_asian,\n",
    "              's_race_other': s_race_other,\n",
    "              's_frpl': s_frpl,\n",
    "              's_sped': s_sped,\n",
    "              's_lep': s_lep,\n",
    "              't_male': t_male,\n",
    "              't_black': t_black,\n",
    "              't_white': t_white,\n",
    "              't_hisp': t_hisp,\n",
    "              't_asian': t_asian,\n",
    "              't_race_other': t_race_other,\n",
    "              't_experience': t_experience,\n",
    "              })\n",
    "df = pd.DataFrame(df)\n",
    "print(\"concat df length : \", len(df))\n",
    "df = df.drop_duplicates()\n",
    "print(\"drop duplicates df length : \", len(df))\n",
    "print(\"standardize  MQI5 and teacher_va\")\n",
    "df = standardize_final_dataset(df, ['MQI5', 'teacher_va'])\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "# teacher demographic : gender(binary), race(multi-class), experience(continuous)\n",
    "# student demographic : gender(binary), race(multi-class), free lunch(binary), special education(binary), english learner(binary)\n",
    "\n",
    "# MQI regression\n",
    "for xlist in ['student_reasoning', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question', 'student_turn_precent', 'student_word_precent']:\n",
    "    df_mqi = df[df[xlist].notna() & df['z_MQI5'].notna()]\n",
    "    print(f\"MQI {xlist} {len(df_mqi)} \")\n",
    "    result = sm.ols(\n",
    "        formula=\n",
    "    \"\"\"z_MQI5 ~ {} + t_male + t_experience + t_race_other + s_male + s_white + s_asian + s_hisp + s_frpl + s_sped + s_lep \"\"\".format(xlist), data=df_mqi).fit()\n",
    "    clustered_results = result.get_robustcov_results(cov_type='cluster', groups=df_mqi['NCTETID'])\n",
    "    coef, std_err = extract_coef_se(clustered_results, xlist)\n",
    "    final_result[xlist]['MQI'] = [coef, std_err]  \n",
    "\n",
    "# teacher value added regression\n",
    "df_va = df[df['teacher_va'].notna()].copy()\n",
    "print(\"doing teacher_va df length : \", len(df_va))\n",
    "# z-scale the teacher_va\n",
    "for xlist in ['student_reasoning', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question', 'student_turn_precent', 'student_word_precent']:\n",
    "    df_val = df_va[df_va[xlist].notna() & df_va['z_teacher_va'].notna()]\n",
    "    print(f\"teacher_va {xlist} {len(df_val)}\")\n",
    "    result = sm.ols(\n",
    "        formula=\n",
    "    \"\"\"z_teacher_va ~ {} + t_male + t_experience + t_race_other + s_male + s_white + s_asian + s_hisp + s_frpl + s_sped + s_lep \"\"\".format(xlist), data=df_val).fit()\n",
    "    clustered_results = result.get_robustcov_results(cov_type='cluster', groups=df_val['NCTETID'])\n",
    "    coef, std_err = extract_coef_se(clustered_results, xlist)\n",
    "    final_result[xlist]['teacher_va'] = [coef, std_err]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833933c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop duplicates df length :  1647\n",
      "standardize clpc, clts, clrsp, clinstd\n",
      "clpc student_reasoning 717\n",
      "clpc student_on_task 744\n",
      "clpc teacher_on_task 744\n",
      "clpc high_uptake 744\n",
      "clpc focusing_question 744\n",
      "clpc student_turn_precent 1647\n",
      "clpc student_word_precent 1647\n",
      "clts student_reasoning 717\n",
      "clts student_on_task 744\n",
      "clts teacher_on_task 744\n",
      "clts high_uptake 744\n",
      "clts focusing_question 744\n",
      "clts student_turn_precent 1647\n",
      "clts student_word_precent 1647\n",
      "clrsp student_reasoning 717\n",
      "clrsp student_on_task 744\n",
      "clrsp teacher_on_task 744\n",
      "clrsp high_uptake 744\n",
      "clrsp focusing_question 744\n",
      "clrsp student_turn_precent 1647\n",
      "clrsp student_word_precent 1647\n",
      "clinstd student_reasoning 717\n",
      "clinstd student_on_task 744\n",
      "clinstd teacher_on_task 744\n",
      "clinstd high_uptake 744\n",
      "clinstd focusing_question 744\n",
      "clinstd student_turn_precent 1647\n",
      "clinstd student_word_precent 1647\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for teacher_id in classroom_obs['NCTETID'].unique():\n",
    "    if teacher_id not in teacher_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    if teacher_id not in student_meta['NCTETID'].unique():\n",
    "        continue\n",
    "    student_metadata_df = student_meta[student_meta['NCTETID'] == teacher_id]\n",
    "    teacher_metadata_df = teacher_meta[teacher_meta['NCTETID'] == teacher_id]\n",
    "    s_male = student_metadata_df['S_MALE'].astype(int).mean()\n",
    "    s_afam = student_metadata_df['S_AFAM'].astype(int).mean()\n",
    "    s_white = student_metadata_df['S_WHITE'].astype(int).mean()\n",
    "    s_hisp = student_metadata_df['S_HISP'].astype(int).mean()\n",
    "    s_asian = student_metadata_df['S_ASIAN'].astype(int).mean()\n",
    "    s_race_other = student_metadata_df['S_RACE_OTHER'].astype(int).mean()\n",
    "    s_frpl = student_metadata_df['S_FRPL'].astype(int).mean()\n",
    "    s_sped = student_metadata_df['S_SPED'].astype(int).mean()\n",
    "    s_lep = student_metadata_df['S_LEP'].astype(int).mean()\n",
    "    t_male = teacher_metadata_df['MALE'].astype(int).mean()\n",
    "    t_black = teacher_metadata_df['BLACK'].astype(int).mean()\n",
    "    t_white = teacher_metadata_df['WHITE'].astype(int).mean()\n",
    "    t_hisp = teacher_metadata_df['HISP'].astype(int).mean()\n",
    "    t_asian = teacher_metadata_df['ASIAN'].astype(int).mean()\n",
    "    t_race_other = teacher_metadata_df['RACEOTHER'].astype(int).mean()\n",
    "    t_experience = teacher_metadata_df['EXPERIENCE'].mean()\n",
    "\n",
    "    classroom_obs_df = classroom_obs[classroom_obs['NCTETID'] == teacher_id]\n",
    "    for obsid in classroom_obs_df['OBSID'].unique():\n",
    "        \n",
    "        clpc = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLPC'].mean()\n",
    "        clts = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLTS'].mean()\n",
    "        clrsp = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLRSP'].mean()\n",
    "        clinstd = classroom_obs_df[classroom_obs_df['OBSID'] == obsid]['CLINSTD'].mean()\n",
    "        student_reasoning = reasoning[reasoning['OBSID'] == obsid]\n",
    "        paired_data = paired[paired['OBSID'] == obsid]\n",
    "        student_on_task = paired_data['student_on_task'].mean()\n",
    "        teacher_on_task = paired_data['teacher_on_task'].mean()\n",
    "        high_uptake = paired_data['high_uptake'].mean()\n",
    "        focusing_question = paired_data['focusing_question'].mean()\n",
    "        observation_dict_df = observation_dict[observation_dict['OBSID'] == obsid]\n",
    "        if len(observation_dict_df) > 0:\n",
    "            student_turn_precent = observation_dict_df['student_turns'].values[0] / observation_dict_df['total_turns'].values[0]\n",
    "            student_word_precent = observation_dict_df['student_words'].values[0] / observation_dict_df['total_words'].values[0]\n",
    "            observation = len(observation_dict_df)\n",
    "        if len(student_reasoning) > 0 or len(paired_data) > 0 or len(observation_dict) > 0:\n",
    "            df.append({'NCTETID': teacher_id,\n",
    "            #  'MQI5': mqi_score,\n",
    "            'clpc': clpc,\n",
    "            'clts': clts,\n",
    "            'clrsp': clrsp,\n",
    "            'clinstd': clinstd,\n",
    "              'student_reasoning': student_reasoning.student_reasoning.mean() if len(student_reasoning) > 0 else None,\n",
    "              'student_on_task': student_on_task if len(paired_data) > 0 else None,\n",
    "              'teacher_on_task': teacher_on_task if len(paired_data) > 0 else None,\n",
    "              'high_uptake': high_uptake if len(paired_data) > 0 else None,\n",
    "              'focusing_question': focusing_question if len(paired_data) > 0 else None,\n",
    "              'student_turn_precent': student_turn_precent if len(observation_dict) > 0 else None,\n",
    "              'student_word_precent': student_word_precent if len(observation_dict) > 0 else None,\n",
    "              'observation': observation if len(observation_dict) > 0 else None,\n",
    "              's_male': s_male,\n",
    "              's_afam': s_afam,\n",
    "              's_white': s_white,\n",
    "              's_hisp': s_hisp,\n",
    "              's_asian': s_asian,\n",
    "              's_race_other': s_race_other,\n",
    "              's_frpl': s_frpl,\n",
    "              's_sped': s_sped,\n",
    "              's_lep': s_lep,\n",
    "              't_male': t_male,\n",
    "              't_black': t_black,\n",
    "              't_white': t_white,\n",
    "              't_hisp': t_hisp,\n",
    "              't_asian': t_asian,\n",
    "              't_race_other': t_race_other,\n",
    "              't_experience': t_experience,\n",
    "              })\n",
    "df = pd.DataFrame(df)\n",
    "df = df.drop_duplicates()\n",
    "print(\"drop duplicates df length : \", len(df))\n",
    "print(\"standardize clpc, clts, clrsp, clinstd\")\n",
    "df = standardize_final_dataset(df, ['clpc', 'clts', 'clrsp', 'clinstd'])\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "\n",
    "# teacher demographic : gender(binary), race(multi-class), experience(continuous)\n",
    "# student demographic : gender(binary), race(multi-class), free lunch(binary), special education(binary), english learner(binary)\n",
    "\n",
    "for ylist in ['clpc', 'clts', 'clrsp', 'clinstd']:\n",
    "    for xlist in ['student_reasoning', 'student_on_task', 'teacher_on_task', 'high_uptake', 'focusing_question', 'student_turn_precent', 'student_word_precent']:\n",
    "        df_mqi = df[df[xlist].notna() & df[f'z_{ylist}'].notna()]\n",
    "        print(f\"{ylist} {xlist} {len(df_mqi)}\")\n",
    "        result = sm.ols(\n",
    "            formula=\n",
    "        \"\"\" z_{} ~ {} + t_male + t_experience + t_race_other + s_male + s_white + s_asian + s_hisp + s_frpl + s_sped + s_lep \"\"\".format(ylist, xlist), data=df_mqi).fit()\n",
    "        clustered_results = result.get_robustcov_results(cov_type='cluster', groups=df_mqi['NCTETID'])\n",
    "        coef, std_err = extract_coef_se(clustered_results, xlist)\n",
    "        final_result[xlist][ylist] = [coef, std_err]\n",
    "# final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0089808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_list = []\n",
    "for xlist in final_result.keys():\n",
    "    one_list = [xlist]\n",
    "    keys = ['teacher_va','MQI', 'clinstd','clts',  'clrsp',  'clpc']\n",
    "    for ylist in keys:\n",
    "        one_list.append(final_result[xlist][ylist][0])\n",
    "        one_list.append(final_result[xlist][ylist][1])\n",
    "    final_result_list.append(one_list)\n",
    "final_result_list = pd.DataFrame(final_result_list,columns=['x','teacher_va_coef','teacher_va_std','MQI_coef','MQI_std','clinstd_coef','clinstd_std','clts_coef','clts_std','clrsp_coef','clrsp_std','clpc_coef','clpc_std'])\n",
    "final_result_list = final_result_list.round(3)\n",
    "x_map = {\n",
    "    'student_reasoning': 'Student Reasoning(1_Our)',\n",
    "    'student_on_task': 'Student on Task(1_Our)',\n",
    "    'teacher_on_task': 'Teacher on Task(1_Our)',\n",
    "    'high_uptake': 'Teacher Uptake(1_Our)',\n",
    "    'focusing_question': 'Focusing Question(1_Our)',\n",
    "    'student_turn_precent': 'Student Turn(1_Our)',\n",
    "    'student_word_precent': 'Student Word(1_Our)',\n",
    "    'observation': 'Observation'\n",
    "}\n",
    "final_result_list['x'] = final_result_list['x'].map(x_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0119f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table5_result = pd.read_csv('paper/table5.csv',sep='\\t')\n",
    "# concat the table5_result and final_result_list, in axis 0\n",
    "merged_result = pd.concat([table5_result, final_result_list], axis=0)\n",
    "merged_result = merged_result.sort_values(by='x').reset_index(drop=True).round(3)\n",
    "def convert_dataframe_to_markdown(df, filename):\n",
    "    # left align the first column\n",
    "    # precision 3, zero decimal\n",
    "    markdown_table = df.to_markdown(index=False, stralign='center')\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(markdown_table)\n",
    "\n",
    "convert_dataframe_to_markdown(merged_result, 'merged_result.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1fa15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ebc5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>teacher_va_coef</th>\n",
       "      <th>teacher_va_std</th>\n",
       "      <th>MQI_coef</th>\n",
       "      <th>MQI_std</th>\n",
       "      <th>clinstd_coef</th>\n",
       "      <th>clinstd_std</th>\n",
       "      <th>clts_coef</th>\n",
       "      <th>clts_std</th>\n",
       "      <th>clrsp_coef</th>\n",
       "      <th>clrsp_std</th>\n",
       "      <th>clpc_coef</th>\n",
       "      <th>clpc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Focusing Question(0_Paper)</td>\n",
       "      <td>0.121*</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.117**</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.083**</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.089**</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.058**</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.079**</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Focusing Question(1_Our)</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student Reasoning(0_Paper)</td>\n",
       "      <td>0.191*</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.313**</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.246**</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.144**</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.173**</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.120**</td>\n",
       "      <td>-0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student Reasoning(1_Our)</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student Turn(0_Paper)</td>\n",
       "      <td>1.044</td>\n",
       "      <td>-1.357</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-0.669</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.574</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Student Turn(1_Our)</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.386</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-1.281</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Student Word(0_Paper)</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.792</td>\n",
       "      <td>0.721+</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>1.132*</td>\n",
       "      <td>-0.541</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.395</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Student Word(1_Our)</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.449</td>\n",
       "      <td>1.161</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Student on Task(0_Paper)</td>\n",
       "      <td>0.038+</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.022*</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.032**</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.033**</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.024**</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.036**</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Student on Task(1_Our)</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Teacher Uptake(0_Paper)</td>\n",
       "      <td>0.234*</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.233**</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.198**</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.132**</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.164**</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.115**</td>\n",
       "      <td>-0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Teacher Uptake(1_Our)</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.093</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Teacher on Task(0_Paper)</td>\n",
       "      <td>0.038+</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.021*</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.030**</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.034**</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.024**</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.035**</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Teacher on Task(1_Our)</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>z_Observations(0_Paper)</td>\n",
       "      <td>523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1554</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             x teacher_va_coef  teacher_va_std MQI_coef  \\\n",
       "0   Focusing Question(0_Paper)          0.121*          -0.050  0.117**   \n",
       "1     Focusing Question(1_Our)           0.263           0.121    0.132   \n",
       "2   Student Reasoning(0_Paper)          0.191*          -0.091  0.313**   \n",
       "3     Student Reasoning(1_Our)          -0.067           0.127    0.436   \n",
       "4        Student Turn(0_Paper)           1.044          -1.357   -0.047   \n",
       "5          Student Turn(1_Our)           -0.08           0.416    1.024   \n",
       "6        Student Word(0_Paper)           0.359          -0.792   0.721+   \n",
       "7          Student Word(1_Our)           0.478           0.516      0.7   \n",
       "8     Student on Task(0_Paper)          0.038+          -0.020   0.022*   \n",
       "9       Student on Task(1_Our)           0.342           0.120    0.332   \n",
       "10     Teacher Uptake(0_Paper)          0.234*          -0.104  0.233**   \n",
       "11       Teacher Uptake(1_Our)            0.02           0.087     0.21   \n",
       "12    Teacher on Task(0_Paper)          0.038+          -0.020   0.021*   \n",
       "13      Teacher on Task(1_Our)           0.326           0.136     0.36   \n",
       "14     z_Observations(0_Paper)             523             NaN     1557   \n",
       "\n",
       "    MQI_std clinstd_coef  clinstd_std clts_coef  clts_std clrsp_coef  \\\n",
       "0    -0.032      0.083**       -0.026   0.089**    -0.019    0.058**   \n",
       "1     0.150        0.163        0.130    -0.093     0.138      0.115   \n",
       "2    -0.066      0.246**       -0.050   0.144**    -0.031    0.173**   \n",
       "3     0.133        0.376        0.105    -0.016     0.105      0.163   \n",
       "4    -0.528        0.718       -0.669     0.214    -0.574      0.125   \n",
       "5     0.365       -0.008        0.386    -0.662     0.376     -0.005   \n",
       "6    -0.413       1.132*       -0.541     0.001    -0.325      0.469   \n",
       "7     0.449        1.161        0.509    -0.075     0.337      0.501   \n",
       "8    -0.010      0.032**       -0.011   0.033**    -0.008    0.024**   \n",
       "9     0.126        0.256        0.129     0.254     0.120     -0.107   \n",
       "10   -0.086      0.198**       -0.072   0.132**    -0.035    0.164**   \n",
       "11    0.087        0.126        0.100     0.131     0.093     -0.012   \n",
       "12   -0.010      0.030**       -0.010   0.034**    -0.008    0.024**   \n",
       "13    0.132        0.241        0.144     0.224     0.119     -0.114   \n",
       "14      NaN         1554          NaN      1554       NaN       1554   \n",
       "\n",
       "    clrsp_std clpc_coef  clpc_std  \n",
       "0      -0.017   0.079**    -0.017  \n",
       "1       0.132     0.048     0.134  \n",
       "2      -0.035   0.120**    -0.035  \n",
       "3       0.123    -0.127     0.116  \n",
       "4      -0.485    -0.172    -0.560  \n",
       "5       0.359    -1.281     0.364  \n",
       "6      -0.395     0.322    -0.387  \n",
       "7       0.387     0.023     0.420  \n",
       "8      -0.007   0.036**    -0.007  \n",
       "9       0.126     0.218     0.115  \n",
       "10     -0.044   0.115**    -0.036  \n",
       "11      0.093     0.102     0.090  \n",
       "12     -0.007   0.035**    -0.007  \n",
       "13      0.133     0.191     0.128  \n",
       "14        NaN      1554       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38cb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
